<!-- Truly understand autograd

Derive chain rule cleanly

Connect computation graph to gradients

Minimal implementation -->

<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reinforcement Learning - Jason Li</title>

    <!-- MathJax for LaTeX math rendering -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>                                                                                                                       
        body {                                                                                                                    
            font-family: Georgia, serif;                                                                                          
            max-width: 700px;                                                                                                     
            margin: 50px auto;                                                                                                    
            padding: 0 20px;                                                                                                      
            line-height: 1.6;                                                                                                     
            color: #333;                                                                                                          
        }                                                                                                                         
        a {                                                                                                                       
            color: #0066cc;                                                                                                       
            text-decoration: none;                                                                                                
        }                                                                                                                         
        a:hover {                                                                                                                 
            text-decoration: underline;                                                                                           
        }                                                                                                                         
    </style>            
</head>
<body>
    <p><a href="../">&larr; Home</a> | <a href="./">&larr; All Posts</a></p>

    <h1>Backpropagation and Automatic Differentiation</h1>
    <p><em>February 2026</em></p>

    <p>
        This is my first blog post. Here I will share my study notes on backpropagation and automatic differentiation.
        We will start with a small example. Then we will explain the undelying mathematics behind them.
    </p>

    <h2>Backpropagation</h2>
    <p>
        Here is an inline equation: \( E = mc^2 \).
    </p>

    <p>And here is a block equation:</p>

    <P>\[\nabla \cdot \mathbf{u} = 0\]</P>

    <p>
        This is the incompressibility condition for fluid flow.
    </p>

    <h2>Automatic Differentiation</h2>
</body>
</html>

